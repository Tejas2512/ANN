{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary library.\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load house price dataset.\n",
    "data = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(data.data, data.target)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalling the dataset.\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_valid = sc.transform(x_valid)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple neural network with single hidden layers.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation='relu', input_shape = x_train.shape[1:], name=\"hidden1\"))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss=keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 82us/step - loss: 1.0154 - val_loss: 0.5214\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 71us/step - loss: 0.4771 - val_loss: 0.4577\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 69us/step - loss: 0.4406 - val_loss: 0.4326\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 77us/step - loss: 0.4209 - val_loss: 0.4178\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.4107 - val_loss: 0.4208\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.4024 - val_loss: 0.4053\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3959 - val_loss: 0.3997\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 75us/step - loss: 0.3917 - val_loss: 0.3977\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3890 - val_loss: 0.3949\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3848 - val_loss: 0.3933\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 75us/step - loss: 0.3843 - val_loss: 0.3891\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3785 - val_loss: 0.3859\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3769 - val_loss: 0.3842\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 73us/step - loss: 0.3731 - val_loss: 0.3827\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3715 - val_loss: 0.3841\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3697 - val_loss: 0.3781\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 75us/step - loss: 0.3673 - val_loss: 0.3809\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 75us/step - loss: 0.3649 - val_loss: 0.3743\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 74us/step - loss: 0.3704 - val_loss: 0.3716\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 73us/step - loss: 0.3619 - val_loss: 0.3727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 35us/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35390584911255873"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frist, we need to create an input object. this is needed because we have multiple inputs.\n",
    "input_ = keras.layers.Input(shape= x_train.shape[1:], name='input')\n",
    "\n",
    "#next create dense layer with 30 neurons and using RELU activation function. \n",
    "#we connect input_ layer with hidden1 and we call it like a fuction.\n",
    "hidden1 = keras.layers.Dense(30, activation='relu', name='hidden1')(input_)\n",
    "\n",
    "#create second hidden layers with same activation function.\n",
    "hidden2 = keras.layers.Dense(30, activation='relu', name='hidden2')(hidden1)\n",
    "\n",
    "#concate hidden layer and input_ layer.\n",
    "concat = keras.layers.Concatenate(name='concate')([input_,hidden2])\n",
    "\n",
    "#create output layer.\n",
    "output = keras.layers.Dense(1,name='output')(concat)\n",
    "\n",
    "#create model by providing inputs and outputs. \n",
    "model = keras.models.Model(inputs = input_, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 30)           270         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 30)           930         hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concate (Concatenate)           (None, 38)           0           input[0][0]                      \n",
      "                                                                 hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            39          concate[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 100us/step - loss: 1.6546 - val_loss: 4.7327\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 89us/step - loss: 0.5941 - val_loss: 0.5664\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 98us/step - loss: 0.4002 - val_loss: 0.3885\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 100us/step - loss: 0.3801 - val_loss: 0.3781\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 106us/step - loss: 0.3693 - val_loss: 0.3719\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 96us/step - loss: 0.3612 - val_loss: 0.3645\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 98us/step - loss: 0.3532 - val_loss: 0.3502\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 96us/step - loss: 0.3444 - val_loss: 0.3444\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 103us/step - loss: 0.3398 - val_loss: 0.4128\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 97us/step - loss: 0.3369 - val_loss: 0.3375\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 98us/step - loss: 0.3285 - val_loss: 0.3301\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 108us/step - loss: 0.3256 - val_loss: 0.3375\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 98us/step - loss: 0.3239 - val_loss: 0.6635\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 101us/step - loss: 0.3480 - val_loss: 0.3674\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 100us/step - loss: 0.3240 - val_loss: 0.3361\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 94us/step - loss: 0.3120 - val_loss: 0.3275\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 102us/step - loss: 0.3123 - val_loss: 0.3360\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 101us/step - loss: 0.3068 - val_loss: 0.3371\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 106us/step - loss: 0.3050 - val_loss: 0.6132\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 97us/step - loss: 0.3069 - val_loss: 0.7049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37327448721079864"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we want to pass 5 feature to input_A and 6 feature to input_B.\n",
    "#saparate features for input_A and input_B \n",
    "x_train_A, x_train_B = x_train[:,:5], x_train[:,2:] \n",
    "x_valid_A, x_valid_B = x_valid[:,:5], x_valid[:,2:]\n",
    "x_test_A, x_test_B = x_test[:,:5], x_test[:,2:]\n",
    "x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frist, we need to create an input object. this is needed because we have multiple inputs A and B.\n",
    "input_A = tf.keras.layers.Input(shape= x_train_A.shape[1:], name='inputA')\n",
    "input_B = tf.keras.layers.Input(shape= x_train_B.shape[1:], name='inputB')\n",
    "\n",
    "#next create dense layer with 30 neurons and using RELU activation function. \n",
    "#we connect input_ layer with hidden1 and we call it like a fuction.\n",
    "hidden1 = tf.keras.layers.Dense(30, activation='relu', name='hidden1')(input_B)\n",
    "\n",
    "#create second hidden layers with same activation function.\n",
    "hidden2 = tf.keras.layers.Dense(30, activation='relu', name='hidden2')(hidden1)\n",
    "\n",
    "#concate hidden layer and input_ layer.\n",
    "concat = tf.keras.layers.Concatenate(name='concat')([input_A, hidden2])\n",
    "\n",
    "#create output layer.\n",
    "output = tf.keras.layers.Dense(1, name='ouput')(concat)\n",
    "\n",
    "#create model by providing inputs and outputs. \n",
    "model = tf.keras.models.Model(inputs = [input_A,input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputB (InputLayer)             [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 30)           210         inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "inputA (InputLayer)             [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 30)           930         hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 35)           0           inputA[0][0]                     \n",
      "                                                                 hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ouput (Dense)                   (None, 1)            36          concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam() ,loss=tf.keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.6798 - val_loss: 0.6531\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5982 - val_loss: 0.4684\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4659 - val_loss: 0.4232\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.3857\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3846 - val_loss: 0.3672\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.3561\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3525\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.3420\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3517 - val_loss: 0.3335\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3298\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3488\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3225\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3208\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3214\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3298 - val_loss: 0.3288\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.3192\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3169\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3290 - val_loss: 0.3201\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3353\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3423 - val_loss: 0.3163\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((np.array(x_train_A), np.array(x_train_B)), \n",
    "                    np.array(y_train), \n",
    "                    epochs=20, \n",
    "                    validation_data=((np.array(x_valid_A), np.array(x_valid_B)) , np.array(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.6142\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((x_test_A,x_test_B),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614164412021637"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((x_new_A,x_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2928553],\n",
       "       [1.5193378],\n",
       "       [1.5324515]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = tf.keras.layers.Input(shape= x_train_A.shape[1:], name='inputA')\n",
    "input_B = tf.keras.layers.Input(shape= x_train_B.shape[1:], name='inputB')\n",
    "hidden1 = tf.keras.layers.Dense(30, activation='relu', name='hidden1')(input_B)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation='relu', name='hidden2')(hidden1)\n",
    "concat = tf.keras.layers.Concatenate(name='concat')([input_A, hidden2])\n",
    "output = tf.keras.layers.Dense(1, name='ouput')(concat)\n",
    "\n",
    "#create aux_output layer\n",
    "aux_output = tf.keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = tf.keras.models.Model(inputs = [input_A,input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputB (InputLayer)             [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 30)           210         inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "inputA (InputLayer)             [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 30)           930         hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 35)           0           inputA[0][0]                     \n",
      "                                                                 hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ouput (Dense)                   (None, 1)            36          concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          hidden2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each output will need its own loss function, so we need to pass list of loss function.\n",
    "#otherwise keras will assume that same loss function must be used for all outputs.\n",
    "#by default keras will compute all losses and add them up to get final training loss.\n",
    "#here we care more about main output than auxlilary output so we specify weigths for each loss.\n",
    "model.compile(optimizer='adam' ,loss=['mse','mse'], loss_weights=[0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3223 - ouput_loss: 0.3169 - aux_output_loss: 0.3706 - val_loss: 0.3140 - val_ouput_loss: 0.3089 - val_aux_output_loss: 0.3607\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3191 - ouput_loss: 0.3134 - aux_output_loss: 0.3708 - val_loss: 0.3151 - val_ouput_loss: 0.3105 - val_aux_output_loss: 0.3564\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3220 - ouput_loss: 0.3166 - aux_output_loss: 0.3708 - val_loss: 0.3137 - val_ouput_loss: 0.3088 - val_aux_output_loss: 0.3584\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - ouput_loss: 0.3128 - aux_output_loss: 0.3689 - val_loss: 0.3075 - val_ouput_loss: 0.3024 - val_aux_output_loss: 0.3533\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3152 - ouput_loss: 0.3094 - aux_output_loss: 0.3673 - val_loss: 0.3070 - val_ouput_loss: 0.3020 - val_aux_output_loss: 0.3514\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - ouput_loss: 0.3129 - aux_output_loss: 0.3681 - val_loss: 0.3069 - val_ouput_loss: 0.3021 - val_aux_output_loss: 0.3499\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3149 - ouput_loss: 0.3091 - aux_output_loss: 0.3673 - val_loss: 0.3123 - val_ouput_loss: 0.3071 - val_aux_output_loss: 0.3593\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3112 - ouput_loss: 0.3054 - aux_output_loss: 0.3641 - val_loss: 0.3062 - val_ouput_loss: 0.3015 - val_aux_output_loss: 0.3486\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3142 - ouput_loss: 0.3086 - aux_output_loss: 0.3643 - val_loss: 0.3031 - val_ouput_loss: 0.2980 - val_aux_output_loss: 0.3487\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3149 - ouput_loss: 0.3093 - aux_output_loss: 0.3648 - val_loss: 0.3019 - val_ouput_loss: 0.2971 - val_aux_output_loss: 0.3448\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3120 - ouput_loss: 0.3061 - aux_output_loss: 0.3655 - val_loss: 0.3135 - val_ouput_loss: 0.3081 - val_aux_output_loss: 0.3621\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3475 - ouput_loss: 0.3430 - aux_output_loss: 0.3879 - val_loss: 0.3033 - val_ouput_loss: 0.2985 - val_aux_output_loss: 0.3471\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3256 - ouput_loss: 0.3207 - aux_output_loss: 0.3704 - val_loss: 0.3086 - val_ouput_loss: 0.3034 - val_aux_output_loss: 0.3550\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3104 - ouput_loss: 0.3048 - aux_output_loss: 0.3606 - val_loss: 0.3006 - val_ouput_loss: 0.2953 - val_aux_output_loss: 0.3482\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3108 - ouput_loss: 0.3050 - aux_output_loss: 0.3621 - val_loss: 0.3016 - val_ouput_loss: 0.2967 - val_aux_output_loss: 0.3458\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3072 - ouput_loss: 0.3014 - aux_output_loss: 0.3595 - val_loss: 0.3060 - val_ouput_loss: 0.3008 - val_aux_output_loss: 0.3527\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3083 - ouput_loss: 0.3027 - aux_output_loss: 0.3591 - val_loss: 0.3105 - val_ouput_loss: 0.3059 - val_aux_output_loss: 0.3520\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3092 - ouput_loss: 0.3037 - aux_output_loss: 0.3580 - val_loss: 0.2990 - val_ouput_loss: 0.2939 - val_aux_output_loss: 0.3446\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3100 - ouput_loss: 0.3044 - aux_output_loss: 0.3601 - val_loss: 0.3037 - val_ouput_loss: 0.2987 - val_aux_output_loss: 0.3483\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3070 - ouput_loss: 0.3014 - aux_output_loss: 0.3573 - val_loss: 0.3037 - val_ouput_loss: 0.2990 - val_aux_output_loss: 0.3469\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_A,x_train_B], \n",
    "                    [y_train,y_train], \n",
    "                    epochs=20,\n",
    "                    validation_data=([x_valid_A,x_valid_B],[y_valid,y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 852us/step - loss: 0.3588 - ouput_loss: 0.3573 - aux_output_loss: 0.3724\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([x_test_A,x_test_B],[y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35882413387298584"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35731932520866394"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37236693501472473"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
